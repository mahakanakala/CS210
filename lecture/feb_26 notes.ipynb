{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS 210 Spring 2024 - Feb 26\n",
    "### Working with CSV Datasets, JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The UCI Iris Dataset - Continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Make sure there are exactly 5 fields in each row (Done on Feb 19)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Make sure all fields except last are real numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 009: Too many fields\n",
      "\t ['4.4', '2', '9', '1.4', '0.2', 'Iris-setosa'] \n",
      "\n",
      "Row 013: Non-numeric value 'N/A'\n",
      "\t ['4.8', 'N/A', '1.4', '0.1', 'Iris-setosa'] \n",
      "\n",
      "Row 035: Non-numeric value 'n/a'\n",
      "\t ['4.9', '3.1', 'n/a', '0.1', 'Iris-setosa'] \n",
      "\n",
      "Row 036: Non-numeric value 'na'\n",
      "\t ['5.0', 'na', '1.2', '0.2', 'Iris-setosa'] \n",
      "\n",
      "Row 043: Non-numeric value '?'\n",
      "\t ['?', '3.2', '1.3', '0.2', 'Iris-setosa'] \n",
      "\n",
      "Row 064: Too few fields\n",
      "\t ['6.1', '4.7', '1.4', 'Iris-versicolor'] \n",
      "\n",
      "Row 070: Non-numeric value 'NA'\n",
      "\t ['5.6', '2.5', '3.9', 'NA', 'Iris-versicolor'] \n",
      "\n",
      "Row 077: Non-numeric value '?'\n",
      "\t ['6.8', '2.8', '?', '1.4', 'Iris-versicolor'] \n",
      "\n",
      "Row 078: Too many fields\n",
      "\t ['6.7', '3.0', '4.5', '1.7', '6.5', 'Iris-versicolor'] \n",
      "\n",
      "Row 103: Too many fields\n",
      "\t ['7', '1', '3.0', '5.9', '2.1', 'Iris-virginica'] \n",
      "\n",
      "Row 113: Too few fields\n",
      "\t ['6.8', '3.0', '5.5', '2.1'] \n",
      "\n",
      "Row 127: Non-numeric value '4x8'\n",
      "\t ['6.2', '2.8', '4x8', '1.8', 'Iris-virginica'] \n",
      "\n",
      "Row 137: Non-numeric value '?'\n",
      "\t ['6.3', '3.4', '5.6', '?', 'Iris-virginica'] \n",
      "\n",
      "Row 148: Non-numeric value ''\n",
      "\t ['', '3.0', '5.2', '2.0', 'Iris-virginica'] \n",
      "\n",
      "Row 152: Too few fields\n",
      "\t [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('iris-messy.csv') as irisfile:\n",
    "    reader = csv.reader(irisfile)\n",
    "    next(reader)                           # skip first line of field names\n",
    "    \n",
    "    for num,row in enumerate(reader):\n",
    "        if len(row) != 5:                  # lines that have too many or too few fields\n",
    "            print(f'Row {(num+1):03}:',end='') \n",
    "            print(' Too few fields') if len(row) < 5 else print(' Too many fields')\n",
    "            print('\\t',row,'\\n')\n",
    "        else:\n",
    "            for val in row[:-1]:           # skip last field\n",
    "                try:\n",
    "                    float(val)\n",
    "                except:\n",
    "                    print(f\"Row {(num+1):03}: Non-numeric value '{val}'\")\n",
    "                    print('\\t',row,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Finalize by writing out acceptable lines:**\n",
    "- Skip lines that have too few or too many fields\n",
    "- Replace non-numeric field with NA (standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('iris-better.csv','w') as outfile:\n",
    "    with open('iris-messy.csv') as irisfile:\n",
    "        \n",
    "        reader = csv.reader(irisfile)\n",
    "        \n",
    "        row = next(reader)                # read first line of field names\n",
    "        outfile.write(','.join(row))\n",
    "        outfile.write('\\n')\n",
    "    \n",
    "        for num,row in enumerate(reader):\n",
    "            if len(row) != 5:             # skip lines that have too many or too few fields\n",
    "                continue\n",
    "            \n",
    "            outrow = []\n",
    "            for val in row[:-1]:      # check all fields except last for numeric\n",
    "                try:\n",
    "                    float(val)\n",
    "                    outrow.append(val)\n",
    "                except:\n",
    "                    outrow.append('NA')\n",
    "\n",
    "            outrow.append(row[-1])    # last field, non-numeric string\n",
    "            outfile.write(','.join(outrow))\n",
    "            outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternatively, you can use a CSV writer to write out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('iris-better.csv','w',newline='') as csvfile:  # note the newline='' parameter\n",
    "    writer = csv.writer(csvfile, delimiter=',')          # set outfile column delimiter to comma, which is the default\n",
    "   \n",
    "    with open('iris-messy.csv') as irisfile:\n",
    "        \n",
    "        reader = csv.reader(irisfile)\n",
    "        \n",
    "        row = next(reader)                               # first line of column names\n",
    "        writer.writerow(row)                             # use writerow method of writer with list of columns as param\n",
    "    \n",
    "        for num,row in enumerate(reader):\n",
    "            if len(row) != 5:                            # lines that have too many or too few columns\n",
    "                continue\n",
    "            \n",
    "            outrow = []\n",
    "            for val in row[:-1]:                         # check all fields except last for numeric\n",
    "                try:\n",
    "                    float(val)\n",
    "                    outrow.append(val)\n",
    "                except:\n",
    "                    outrow.append('NA')\n",
    "            outrow.append(row[-1])                      # last field, non-numeric string\n",
    "            writer.writerow(outrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3: Processing auto-mpg CSV file Using DictReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mpg': '18.0', 'cylinders': '8.', 'displacement': '307.0', 'horsepower': '130.0', 'weight': '3504.', 'acceleration': '12.0', 'model year': '70.', 'origin': '1.', 'car name': 'chevrolet chevelle malibu'}\n",
      "{'mpg': '15.0', 'cylinders': '8.', 'displacement': '350.0', 'horsepower': '165.0', 'weight': '3693.', 'acceleration': '11.5', 'model year': '70.', 'origin': '1.', 'car name': 'buick skylark 320'}\n",
      "{'mpg': '18.0', 'cylinders': '8.', 'displacement': '318.0', 'horsepower': '150.0', 'weight': '3436.', 'acceleration': '11.0', 'model year': '70.', 'origin': '1.', 'car name': 'plymouth satellite'}\n",
      "{'mpg': '16.0', 'cylinders': '8.', 'displacement': '304.0', 'horsepower': '150.0', 'weight': '3433.', 'acceleration': '12.0', 'model year': '70.', 'origin': '1.', 'car name': 'amc rebel sst'}\n",
      "{'mpg': '17.0', 'cylinders': '8.', 'displacement': '302.0', 'horsepower': '140.0', 'weight': '3449.', 'acceleration': '10.5', 'model year': '70.', 'origin': '1.', 'car name': 'ford torino'}\n"
     ]
    }
   ],
   "source": [
    "# Using DictReader on csv\n",
    "# This gives an OrderedDictionary for each row\n",
    "reader = csv.DictReader(open('auto_mpg_original.csv'))\n",
    "for index,row in enumerate(reader):\n",
    "    print(row)\n",
    "    if index > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note that the double quotes around the car name have been stripped off*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print header column names, and all lines that have an NA for any of the fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'car name']\n",
      "mpg,cylinders,displacement,horsepower,weight,acceleration,model year,origin,car name\n",
      "NA,4.,133.0,115.0,3090.,17.5,70.,2.,\"citroen ds-21 pallas\"\n",
      "NA,8.,350.0,165.0,4142.,11.5,70.,1.,\"chevrolet chevelle concours (sw)\"\n",
      "NA,8.,351.0,153.0,4034.,11.0,70.,1.,\"ford torino (sw)\"\n",
      "NA,8.,383.0,175.0,4166.,10.5,70.,1.,\"plymouth satellite (sw)\"\n",
      "NA,8.,360.0,175.0,3850.,11.0,70.,1.,\"amc rebel sst (sw)\"\n",
      "NA,8.,302.0,140.0,3353.,8.0,70.,1.,\"ford mustang boss 302\"\n",
      "25.0,4.,98.00,NA,2046.,19.0,71.,1.,\"ford pinto\"\n",
      "NA,4.,97.00,48.00,1978.,20.0,71.,2.,\"volkswagen super beetle 117\"\n",
      "21.0,6.,200.0,NA,2875.,17.0,74.,1.,\"ford maverick\"\n",
      "40.9,4.,85.00,NA,1835.,17.3,80.,2.,\"renault lecar deluxe\"\n",
      "23.6,4.,140.0,NA,2905.,14.3,80.,1.,\"ford mustang cobra\"\n",
      "34.5,4.,100.0,NA,2320.,15.8,81.,2.,\"renault 18i\"\n",
      "NA,4.,121.0,110.0,2800.,15.4,81.,2.,\"saab 900s\"\n",
      "23.0,4.,151.0,NA,3035.,20.5,82.,1.,\"amc concord dl\"\n"
     ]
    }
   ],
   "source": [
    "# using fieldnames and values methods\n",
    "reader = csv.DictReader(open('auto_mpg_original.csv'))\n",
    "print(reader.fieldnames)\n",
    "print(','.join(reader.fieldnames))\n",
    "for row in reader:\n",
    "    values = list(row.values())  # row.values() is an odict.values object, need to cast to list\n",
    "    if 'NA' in values:\n",
    "        values[-1] = '\"' + values[-1] + '\"'\n",
    "        print(','.join(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write out a cleaned up version into a CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reader = csv.DictReader(open('auto_mpg_original.csv'))  # input, has a bunch of NAs for values\n",
    "with open('auto_mpg.csv','w') as csvfile:               # output, delete lines with NA for any value\n",
    "    csvfile.write(','.join(reader.fieldnames)+'\\n')     # header line with field names    \n",
    "    for row in reader:\n",
    "        if 'NA' in row.values():\n",
    "            continue\n",
    "        values = list(row.values())\n",
    "        csvfile.write(','.join(values)+'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternatively, you can use a CSV DictWriter writer to write out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('auto_mpg_original.csv') as csvfile: \n",
    "    reader = csv.DictReader(csvfile)\n",
    "    \n",
    "    with open('auto_mpg.csv','w',newline='') as csvout:\n",
    "        # fieldnames is a required parameter for DictWriter\n",
    "        writer = csv.DictWriter(csvout,fieldnames=reader.fieldnames, delimiter='\\t')  \n",
    "        writer.writeheader()   \n",
    "        for row in reader:\n",
    "            if 'NA' in row.values():\n",
    "                continue\n",
    "            writer.writerow(row)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"brown\">Working with JSON (JavaScript Object Notation) Datasets</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Loading a JSON-formatted string into a JSON object</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hill center': 'Busch', 'AB': 'College Ave'}\n",
      "dict_keys(['hill center', 'AB'])\n",
      "dict_values(['Busch', 'College Ave'])\n"
     ]
    }
   ],
   "source": [
    "json1 = '{\"hill center\":\"Busch\", \"AB\":\"College Ave\"}'   # a string containing dictionary formatted data\n",
    "# load this into Python\n",
    "dict1 = json.loads(json1)\n",
    "print(dict1)\n",
    "print(dict1.keys())\n",
    "print(dict1.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m json1 \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhill center\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBusch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAB\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollege Ave\u001b[39m\u001b[38;5;124m\"\u001b[39m}   \n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# load this into Python\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m dict1 \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(dict1)\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/json/__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[0;32m--> 339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    340\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not dict"
     ]
    }
   ],
   "source": [
    "json1 = {\"hill center\":\"Busch\", \"AB\":\"College Ave\"}   \n",
    "# load this into Python\n",
    "dict1 = json.loads(json1)\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Above doesn't work - the input must be a string, so need quotes around the whole thing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m json1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m2:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBusch\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, 1:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollege Ave\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m  \n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# load this into Python\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m dict1 \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(dict1)\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)"
     ]
    }
   ],
   "source": [
    "json1 = '{2:\"Busch\", 1:\"College Ave\"}'  \n",
    "# load this into Python\n",
    "dict1 = json.loads(json1)\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keys are required to be strings, so the numbers 2 and 1 as keys are rejected**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But values are not required to be strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'John': 12, 'Jane': 25}\n"
     ]
    }
   ],
   "source": [
    "json1 = '{\"John\":12, \"Jane\":25}'   # but values need not be strings\n",
    "# load this into Python\n",
    "dict1 = json.loads(json1)\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John', 'age': 30, 'city': 'New York'}\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "x =  '{ \"name\":\"John\", \"age\":30, \"city\":\"New York\"}'\n",
    "y = json.loads(x)\n",
    "print(y)\n",
    "print(y[\"age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key strings are required to be double-quoted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 3 (char 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJohn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:30, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew York\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 3 (char 2)"
     ]
    }
   ],
   "source": [
    "x =  \"{ 'name':'John', 'age':30, 'city':'New York'}\"\n",
    "y = json.loads(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Above doesn't work, because key strings are required to be double-quoted**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Dumping a dictonary to JSON-formatted string</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"Jane\", \"age\": 25, \"city\": \"Chicago\"}\n"
     ]
    }
   ],
   "source": [
    "dat_dict = { 'name' : 'Jane', 'age' : 25, 'city' : 'Chicago'}\n",
    "dat_str = json.dumps(dat_dict)\n",
    "print(dat_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 'busch', 1: 'college ave'}\n"
     ]
    }
   ],
   "source": [
    "# a dictionary with integers for keys\n",
    "dict2 = {2: 'busch', 1: 'college ave'}\n",
    "print(dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"2\": \"busch\", \"1\": \"college ave\"}\n"
     ]
    }
   ],
   "source": [
    "# dump to string \n",
    "dict2_str = json.dumps(dict2)\n",
    "print(dict2_str)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"red\">1. When dumping, integer keys converted to strings, single-quoted strings are double-quoted</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2': 'busch', '1': 'college ave'}\n"
     ]
    }
   ],
   "source": [
    "dict2_new = json.loads(dict2_str)\n",
    "print(dict2_new)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"red\">2. So when loading back, dict keys change to strings so dict2 is NOT the same as dict2_new<font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Using arrays as values</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "# array of integers\n",
    "json3 = '{\"name\": \"Anika\", \"quiz_scores\":[38,40,36,40,32]}'\n",
    "dict3 = json.loads(json3)\n",
    "print(dict3['quiz_scores'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quiz_scores': [{'name': 'Anika', 'scores': [38, 40, 36, 40, 32]}, {'name': 'Amir', 'scores': [36, 38, 40, 30, 34]}]}\n"
     ]
    }
   ],
   "source": [
    "# array of dictionaries\n",
    "json4 = '{\"quiz_scores\" : [{\"name\": \"Anika\", \"scores\": [38,40,36,40,32]}, {\"name\": \"Amir\", \"scores\":[36,38,40,30,34]}]}'\n",
    "dict4 = json.loads(json4)\n",
    "print(dict4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amir\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(dict4['quiz_scores'][1]['name'])  # name of second item in quiz_scores value array\n",
    "print(dict4['quiz_scores'][0]['scores'][3])  # 4th score of first item in quiz_scores value array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Storing JSON to file</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dump to file\n",
    "with open (\"quiz_scores.json\",\"w\") as qsfile:\n",
    "    json.dump(dict4, qsfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you open the quiz_scores.json file with Editor, it looks like this:**\n",
    "\n",
    "{\"quiz_scores\": [{\"name\": \"Anika\", \"scores\": [38, 40, 36, 40, 32]}, {\"name\": \"Amir\", \"scores\": [36, 38, 40, 30, 34]}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**But if you just double-click on it (same as open with JSON), it will show you a hierarchical structure that is much easier to comprehend. Try it out for yourself.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load from file\n",
    "with open(\"quiz_scores.json\") as qsfile:\n",
    "    qs_scores = json.load(qsfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quiz_scores': [{'name': 'Anika', 'scores': [38, 40, 36, 40, 32]}, {'name': 'Amir', 'scores': [36, 38, 40, 30, 34]}]}\n"
     ]
    }
   ],
   "source": [
    "print(qs_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">JSON with just a string (no dictionary)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JSON - JavaScript Object Notation'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonstr = json.loads('\"JSON - JavaScript Object Notation\"')\n",
    "jsonstr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that the string must be double-quoted since the JSON format itself requires a single-quote around the whole contents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">JSON with just an array</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 4]\n",
      "4\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "jsonarr = json.loads('[1,2,2,4]')\n",
    "print(jsonarr)\n",
    "print(len(jsonarr))\n",
    "print(type(jsonarr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">JSON with just a number</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "jsonint = json.loads('25')\n",
    "print(type(jsonint))\n",
    "jsonreal = json.loads('25.3')\n",
    "print(type(jsonreal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 1 column 3 (char 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m12.x\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 3 (char 2)"
     ]
    }
   ],
   "source": [
    "json.loads('12.x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12.x'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads('\"12.x\"')   # this is a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">JSON with just a boolean</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "jsonbool = json.loads('true')   # must be lowercase\n",
    "print(jsonbool)\n",
    "print(type(jsonbool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">JSON with a null</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "jsonnull = json.loads('null')\n",
    "print(jsonnull)\n",
    "print(type(jsonnull))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Exercise: ad hoc file format converted to JSON\n",
    "\n",
    "Suppose scores were in a file *qs_scores.txt*, like this:\n",
    "    \n",
    "Anika Sorenson|38,40,36,40,32<br>\n",
    "Amir Sharif|36,38,40,30,34\n",
    "\n",
    "We want to store this in JSON form so that it is standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Anika Sorenson': [38, 40, 36, 40, 32], 'Amir Sharif': [36, 38, 40, 30, 34]}\n"
     ]
    }
   ],
   "source": [
    "# make an input text file, qs-scores.txt\n",
    "qs_dict = {}\n",
    "for line in open('qs_scores.txt'):\n",
    "    flds = line.split('|')\n",
    "    scores = flds[1].strip().split(',')\n",
    "    qs_scores = [int(qs) for qs in scores]\n",
    "    qs_dict[flds[0].strip()] = qs_scores\n",
    "print(qs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('qs_scores.json','w') as qsfile:\n",
    "    json.dump(qs_dict, qsfile)\n",
    "\n",
    "# double-click the output file, will open in json interpretation mode\n",
    "# right-click -> open with editor, can see plain text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Getting JSON data from a Web page<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of reading public JSON dataset\n",
    "\n",
    "Nobel Prizes - http://api.nobelprize.org/v1/prize.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nobel_url = 'http://api.nobelprize.org/v1/prize.json'\n",
    "resp = requests.get(nobel_url)\n",
    "nobels = json.loads(resp.text)\n",
    "with open('nobels.json','w') as nobels_file:\n",
    "    json.dump(nobels, nobels_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nobels is a dictionary with a single key, 'prizes'<br>Explore the nobels.json file to get a feel for the data structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['prizes'])\n"
     ]
    }
   ],
   "source": [
    "print(nobels.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the value for 'prizes' is a list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nobels['prizes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**list is of length 670, one item per prize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'year': '2023', 'category': 'chemistry', 'laureates': [{'id': '1029', 'firstname': 'Moungi', 'surname': 'Bawendi', 'motivation': '\"for the discovery and synthesis of quantum dots\"', 'share': '3'}, {'id': '1030', 'firstname': 'Louis', 'surname': 'Brus', 'motivation': '\"for the discovery and synthesis of quantum dots\"', 'share': '3'}, {'id': '1031', 'firstname': 'Aleksey', 'surname': 'Yekimov', 'motivation': '\"for the discovery and synthesis of quantum dots\"', 'share': '3'}]}\n"
     ]
    }
   ],
   "source": [
    "# print nobel prizes for the latest year (2023)\n",
    "print(nobels['prizes'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Each list item is a dictionary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"brown\">Get all prizes awarded in the year 2021</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'year': '2021', 'category': 'chemistry', 'laureates': [{'id': '1002', 'firstname': 'Benjamin', 'surname': 'List', 'motivation': '\"for the development of asymmetric organocatalysis\"', 'share': '2'}, {'id': '1003', 'firstname': 'David', 'surname': 'MacMillan', 'motivation': '\"for the development of asymmetric organocatalysis\"', 'share': '2'}]}, {'year': '2021', 'category': 'economics', 'laureates': [{'id': '1007', 'firstname': 'David', 'surname': 'Card', 'motivation': '\"for his empirical contributions to labour economics\"', 'share': '2'}, {'id': '1008', 'firstname': 'Joshua', 'surname': 'Angrist', 'motivation': '\"for their methodological contributions to the analysis of causal relationships\"', 'share': '4'}, {'id': '1009', 'firstname': 'Guido', 'surname': 'Imbens', 'motivation': '\"for their methodological contributions to the analysis of causal relationships\"', 'share': '4'}]}, {'year': '2021', 'category': 'literature', 'laureates': [{'id': '1004', 'firstname': 'Abdulrazak', 'surname': 'Gurnah', 'motivation': '\"for his uncompromising and compassionate penetration of the effects of colonialism and the fate of the refugee in the gulf between cultures and continents\"', 'share': '1'}]}, {'year': '2021', 'category': 'peace', 'laureates': [{'id': '1005', 'firstname': 'Maria', 'surname': 'Ressa', 'motivation': '\"for their efforts to safeguard freedom of expression, which is a precondition for democracy and lasting peace\"', 'share': '2'}, {'id': '1006', 'firstname': 'Dmitry', 'surname': 'Muratov', 'motivation': '\"for their efforts to safeguard freedom of expression, which is a precondition for democracy and lasting peace\"', 'share': '2'}]}, {'year': '2021', 'category': 'physics', 'overallMotivation': '\"for groundbreaking contributions to our understanding of complex physical systems\"', 'laureates': [{'id': '999', 'firstname': 'Syukuro', 'surname': 'Manabe', 'motivation': '\"for the physical modelling of Earths climate, quantifying variability and reliably predicting global warming\"', 'share': '4'}, {'id': '1000', 'firstname': 'Klaus', 'surname': 'Hasselmann', 'motivation': '\"for the physical modelling of Earths climate, quantifying variability and reliably predicting global warming\"', 'share': '4'}, {'id': '1001', 'firstname': 'Giorgio', 'surname': 'Parisi', 'motivation': '\"for the discovery of the interplay of disorder and fluctuations in physical systems from atomic to planetary scales\"', 'share': '2'}]}, {'year': '2021', 'category': 'medicine', 'laureates': [{'id': '997', 'firstname': 'David', 'surname': 'Julius', 'motivation': '\"for their discoveries of receptors for temperature and touch\"', 'share': '2'}, {'id': '998', 'firstname': 'Ardem', 'surname': 'Patapoutian', 'motivation': '\"for their discoveries of receptors for temperature and touch\"', 'share': '2'}]}]\n"
     ]
    }
   ],
   "source": [
    "nobels_2021 = [prize for prize in nobels['prizes'] if prize['year'] == '2021']\n",
    "print(nobels_2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is TMI and quite hard to read, we want to write in a user-friendly format**\n",
    "\n",
    "**We want:**<br>\n",
    "    Chemistry: name1, name2 ...<br>\n",
    "    Economics: name1, name2 ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemistry: Benjamin List, David MacMillan\n",
      "Economics: David Card, Joshua Angrist, Guido Imbens\n",
      "Literature: Abdulrazak Gurnah\n",
      "Peace: Maria Ressa, Dmitry Muratov\n",
      "Physics: Syukuro Manabe, Klaus Hasselmann, Giorgio Parisi\n",
      "Medicine: David Julius, Ardem Patapoutian\n"
     ]
    }
   ],
   "source": [
    "for prize in nobels_2021:\n",
    "    print(prize['category'].capitalize() + ': ',end='')\n",
    "    winners = [winner['firstname']+' '+winner['surname'] for winner in prize['laureates']]\n",
    "    print(', '.join(winners))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"brown\">Get all prizes awarded in the year 2020</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemistry: Emmanuelle Charpentier, Jennifer A. Doudna\n",
      "Economics: Paul Milgrom, Robert Wilson\n",
      "Literature: Louise Glck\n",
      "Peace: "
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'surname'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prize \u001b[38;5;129;01min\u001b[39;00m nobels_2020:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(prize[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcapitalize() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m,end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     winners \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mwinner\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirstname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mwinner\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msurname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwinner\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlaureates\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(winners))\n",
      "Cell \u001b[0;32mIn[37], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prize \u001b[38;5;129;01min\u001b[39;00m nobels_2020:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(prize[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcapitalize() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m,end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     winners \u001b[38;5;241m=\u001b[39m [winner[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirstname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[43mwinner\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msurname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m winner \u001b[38;5;129;01min\u001b[39;00m prize[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaureates\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(winners))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'surname'"
     ]
    }
   ],
   "source": [
    "nobels_2020 = [prize for prize in nobels['prizes'] if prize['year'] == '2020']\n",
    "for prize in nobels_2020:\n",
    "    print(prize['category'].capitalize() + ': ',end='')\n",
    "    winners = [winner['firstname']+' '+winner['surname'] for winner in prize['laureates']]\n",
    "    print(', '.join(winners))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Surname missing in Peace prize, could be missing in other years as well<br>\n",
    "Use dict get method with default return of empty string if key not found**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemistry: Emmanuelle Charpentier, Jennifer A. Doudna\n",
      "Economics: Paul Milgrom, Robert Wilson\n",
      "Literature: Louise Glck\n",
      "Peace: World Food Programme \n",
      "Physics: Roger Penrose, Reinhard Genzel, Andrea Ghez\n",
      "Medicine: Harvey Alter, Michael Houghton, Charles Rice\n"
     ]
    }
   ],
   "source": [
    "for prize in nobels_2020:\n",
    "    print(prize['category'].capitalize() + ': ',end='')\n",
    "    winners = [winner['firstname']+' '+winner.get('surname','') for winner in prize['laureates']]\n",
    "    print(', '.join(winners))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Basic JSON structure: https://www.json.org/json-en.html</font>\n",
    "As the description says at the top, JSON is built on two structures, which in Python vernacular are dictionaries (key-value pairs), and lists (arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
