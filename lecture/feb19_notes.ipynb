{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS 210 Spring 2024 - Feb 19\n",
    "### Regular expressions Continued, Plain Text and CSV Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Pre-compiling a regular expression</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sometimes it's easier to \"compile\" a regular expression and use it several times later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('848', '445-2790')\n"
     ]
    }
   ],
   "source": [
    "pattrn = re.compile(r'\\s*\\((\\d{3})\\)(\\d{3}-\\d{4})\\s*')\n",
    "res = pattrn.match('(848)445-2790')\n",
    "print(res.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('25',)\n",
      "('25',)\n",
      "('25',)\n"
     ]
    }
   ],
   "source": [
    "patt = re.compile(r'\\s*#?\\s*(\\d+)')\n",
    "res = patt.match('#25 Infinite Loop,Cupertino,CA 12345')\n",
    "print(res.groups())\n",
    "res = patt.match(' # 25 Infinite Loop,Cupertino,CA 12345')\n",
    "print(res.groups())\n",
    "res = patt.match(' 25 Infinite Loop,Cupertino,CA 12345')\n",
    "print(res.groups())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "<pre>\n",
    "Given a string of the form:\n",
    "     '\"&lt;last name>, &lt;first name>\",&lt;netid>'\n",
    "\n",
    "Output the string:\n",
    "     '&lt;first name>,&lt;last name>,&lt;netid>'\n",
    "\n",
    "e.g. '\"  Venugopal,   Sesh \", sv123 ' => 'Sesh,Venugopal,sv123@rutgers.edu'\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sesh,Venugopal,sv123@rutgers.edu\n"
     ]
    }
   ],
   "source": [
    "# capture the last name, first name and netid and use the captures to construct result\n",
    "# allow for leading and trailing whitespaces around name and netid, and whitespaces around comma separators \n",
    "student_str = '\"  Venugopal ,   Sesh \" , sv123 '\n",
    "res = re.sub(r'\"\\s*(\\S+)\\s*,\\s*(\\S+)\\s*\"\\s*,\\s*(\\w+)\\s*',r'\\2,\\1,\\3@rutgers.edu',student_str)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "invalid group reference 2 at position 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m student_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Venugopal,   Sesh \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, sv123 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m target \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS*)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*,\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS*)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*,\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw*)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m repl \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m2,\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m1,\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m3@rutgers.edu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m res \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(target,repl,student_str)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/re/__init__.py:227\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(pattern, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompile a regular expression pattern, returning a Pattern object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/re/__init__.py:294\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe re.TEMPLATE/re.T flag is deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is an undocumented flag \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout an obvious purpose. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    293\u001b[0m               \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m--> 294\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43m_compiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (flags \u001b[38;5;241m&\u001b[39m DEBUG):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_cache) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m _MAXCACHE:\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# Drop the oldest item\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/re/_compiler.py:743\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[1;32m    742\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[0;32m--> 743\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43m_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    745\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/re/_parser.py:980\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    977\u001b[0m state\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m flags\n\u001b[1;32m    978\u001b[0m state\u001b[38;5;241m.\u001b[39mstr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[0;32m--> 980\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_sub\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSRE_FLAG_VERBOSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m fix_flags(\u001b[38;5;28mstr\u001b[39m, p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags)\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/re/_parser.py:455\u001b[0m, in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    453\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     itemsappend(\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/re/_parser.py:539\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m this[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 539\u001b[0m     code \u001b[38;5;241m=\u001b[39m \u001b[43m_escape\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m     subpatternappend(code)\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m this \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SPECIAL_CHARS:\n",
      "File \u001b[0;32m/usr/lib/anaconda3/lib/python3.11/re/_parser.py:435\u001b[0m, in \u001b[0;36m_escape\u001b[0;34m(source, escape, state)\u001b[0m\n\u001b[1;32m    433\u001b[0m         state\u001b[38;5;241m.\u001b[39mchecklookbehindgroup(group, source)\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m GROUPREF, group\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid group reference \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m group, \u001b[38;5;28mlen\u001b[39m(escape) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(escape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m ASCIILETTERS:\n",
      "\u001b[0;31merror\u001b[0m: invalid group reference 2 at position 1"
     ]
    }
   ],
   "source": [
    "# what if try pre-compiling both the strings?\n",
    "student_str = '\"  Venugopal,   Sesh \", sv123 '\n",
    "target = re.compile(r'\"\\s*(\\S*)\\s*,\\s*(\\S*)\\s*\"\\s*,\\s*(\\w*)')\n",
    "repl = re.compile(r'\\2,\\1,\\3@rutgers.edu')\n",
    "res = re.sub(target,repl,student_str)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above doesn't work: the context of the pattern is restricted to the target variable, so the references to the captured groups in the repl variable are out of context**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Verbose, multiline regexp</font>\n",
    "Suppose we want to do some capturing in an address of the form<br>\n",
    "`<optional #><apt num><whitespace><street name>,<city>,<2 character upper case state code><whitespace><zip>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "addr = re.compile(r\"\"\"\n",
    "        \\s*             # possible leading white space\n",
    "        \\#?             # optional, use \\ before # to disambiguate from comment #\n",
    "        \\s*             # possible whitespace\n",
    "        (\\d+)           # capture apt number\n",
    "        \\s+             # at least one white space \n",
    "        (.*)?,          # capture street name, non-greedy sequence until ',', \n",
    "        \\s*             # possible whitespace\n",
    "        (.*)?,          # capture city name, non-greedy sequence until ',', \n",
    "        \\s*             # possible white space\n",
    "        ([A-Z]{2})      # capture state code\n",
    "        \\s*             # possible white space\n",
    "        (\\d{5})         # capture zip code\n",
    "        \\s*             # possible trailing whitespace\n",
    "        $               # end of string\n",
    "        \"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "Infinite Loop\n",
      "Cupertino\n",
      "CA\n",
      "12345\n"
     ]
    }
   ],
   "source": [
    "res = addr.match(' # 25 Infinite Loop,Cupertino,CA 12345')\n",
    "if res:\n",
    "    for gr in res.groups():\n",
    "        print(gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "Infinite Loop\n",
      "Cupertino \n",
      "CA\n",
      "12345\n"
     ]
    }
   ],
   "source": [
    "res = addr.match('#25 Infinite Loop,  Cupertino , CA 12345')\n",
    "if res:\n",
    "    for gr in res.groups():\n",
    "        print(gr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Naming captured fields</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Can give names to the captured fields for easier access, using ?P in group\n",
    "named_addr = re.compile(r\"\"\"\n",
    "        \\s*             # possible leading white space\n",
    "        \\#?             # optional, use \\ before # to disambiguate from comment #\n",
    "        \\s*             # possible whitespace\n",
    "        (?P<apt>\\d+)    # capture apt number\n",
    "        \\s+             # at least one white space \n",
    "        (?P<street>.*)?, # capture street name, non-greedy sequence until ',', \n",
    "        \\s*             # possible whitespace\n",
    "        (?P<city>.*)?,  # capture city name, non-greedy sequence until ',', \n",
    "        \\s*             # possible white space\n",
    "        (?P<state>[A-Z]{2})      # capture state code\n",
    "        \\s*             # possible white space\n",
    "        (?P<zip>\\d{5})  # capture zip code\n",
    "        \\s*             # possible trailing whitespace\n",
    "        $               # end of string\n",
    "        \"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'apt': '10',\n",
       " 'street': 'California Avenue',\n",
       " 'city': 'Palo Alto',\n",
       " 'state': 'CA',\n",
       " 'zip': '94304'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = named_addr.match(' # 10 California Avenue,Palo Alto,CA 94304')\n",
    "# print(res.groups()[0])\n",
    "res.groupdict()  # groupdict method gives group name -> value mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Suppressing captures</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Can suppress capture using ?: inside group\n",
    "named_addr = re.compile(r\"\"\"\n",
    "        \\s*             # possible leading white space\n",
    "        \\#?             # optional, use \\ before # to disambiguate from comment #\n",
    "        \\s*             # possible whitespace\n",
    "        (?:\\d+)         # don't capture apt num\n",
    "        \\s+             # at least one white space \n",
    "        (?:.*)?,        # don't capture street \n",
    "        \\s*             # possible whitespace\n",
    "        (?P<city>.*)?,  # capture city name, name it as 'city'\n",
    "        \\s*             # possible white space\n",
    "        (?P<state>[A-Z]{2})      # capture state code, name it as 'state'\n",
    "        \\s*             # possible white space\n",
    "        (?:\\d{5})       # don't capture zip code\n",
    "        \\s*             # possible trailing whitespace\n",
    "        $               # end of string\n",
    "        \"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'city': 'Palo Alto', 'state': 'CA'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = named_addr.match(' #10 California Avenue,Palo Alto,CA 94304')\n",
    "res.groupdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can, of course, get rid of the () for capture altogether** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Can suppress capture using ?: inside group\n",
    "named_addr = re.compile(r\"\"\"\n",
    "        \\s*             # possible leading white space\n",
    "        \\#?             # optional, use \\ before # to disambiguate from comment #\n",
    "        \\s*             # possible whitespace\n",
    "        \\d+             # don't capture apt num\n",
    "        \\s+             # at least one white space \n",
    "        .*?,            # don't capture street \n",
    "        \\s*             # possible whitespace\n",
    "        (?P<city>.*)?,  # capture city name, name it as 'city'\n",
    "        \\s*             # possible white space\n",
    "        (?P<state>[A-Z]{2})      # capture state code, name it as 'state'\n",
    "        \\s*             # possible white space\n",
    "        \\d{5}           # don't capture zip code\n",
    "        \\s*             # possible trailing whitespace\n",
    "        $               # end of string\n",
    "        \"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'city': 'Palo Alto', 'state': 'CA'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = named_addr.match(' #10 California Avenue,Palo Alto,CA 94304')\n",
    "res.groupdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But the reason you may want to keep them is you can then turn captures on and off as needed** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Back referencing captures using name</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(5, 19), match='air or hot air'>\n"
     ]
    }
   ],
   "source": [
    "# Captured string can be back referenced\n",
    "backref = re.compile(r\"\"\"\n",
    "            (?P<air>air)     # capture the string 'air', name it as 'air'\n",
    "            .*               # greedy\n",
    "            (?P=air)         # capture backrefernce to previous name 'air'\n",
    "            \"\"\", re.VERBOSE)\n",
    "res = backref.search('cool air or hot air')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(5, 19), match='air or hot air'>\n"
     ]
    }
   ],
   "source": [
    "res = backref.search('cool air or hot air')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "res = backref.search('cool air or hot')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Using findall and finditer functions to get all matches</font>\n",
    "- findall constructs the entire list of matches before returning it\n",
    "- finditer returns one match at a time, on demand, in a Match object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"brown\">findall()</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['These', 'are', 'the', 'days', 'of', 'miracles', 'and', 'wonders']\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "res = re.findall(r'\\w+','These are the days of miracles and wonders!')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'can', 't', 'believe', 'it']\n"
     ]
    }
   ],
   "source": [
    "# Example 2-a\n",
    "res = re.findall(r'\\w+',\"I can't believe it\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"can't\", 'believe', 'it']\n"
     ]
    }
   ],
   "source": [
    "# Example 2-b\n",
    "res = re.findall(r'\\S+',\"I can't believe it\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"brown\">finditer()</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<callable_iterator object at 0x7f10f873d120>\n",
      "These @ (0, 5)\n",
      "are @ (6, 9)\n",
      "the @ (10, 13)\n",
      "days @ (14, 18)\n",
      "of @ (19, 21)\n",
      "miracles @ (22, 30)\n",
      "and @ (31, 34)\n",
      "wonders @ (35, 42)\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "iterator = re.finditer(r'\\w+','These are the days of miracles and wonders!')\n",
    "print(iterator)\n",
    "for match in iterator:\n",
    "    print(match.group(),'@',match.span())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I @ (0, 1)\n",
      "can't @ (2, 7)\n",
      "believe @ (8, 15)\n",
      "it @ (16, 18)\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "iterator = re.finditer(r'\\S+',\"I can't believe it\")\n",
    "for match in iterator:\n",
    "    print(match.group(),'@',match.span())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"brown\">Working with Plain Text and CSV Datasets</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: UCI Auto MPG dataset - Plain Text File\n",
    "\n",
    "[Auto MPG](https://archive.ics.uci.edu/dataset/9/auto+mpg)\n",
    "\n",
    "In the text file auto-mpg-original.txt there are several fields in each line. \n",
    "Of these we want the mpg (first field), cylinders (second field),\n",
    "the model year (third to last), and car name (last). \n",
    "We want to read lines from this file, and write these \n",
    "fields out in the following format:\n",
    "<pre>\n",
    "\"car name\",year (19xx),cylinders (int),mpg\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 1: Using Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_str='18.0   8.   307.0      130.0      3504.      12.0   70.  1.\t\"chevrolet chevelle malibu\"'\n",
    "\n",
    "car_reg = re.compile(r\"\"\"\n",
    "                \\s*                    # skip over leading whitespaces, if any\n",
    "                (?P<mpg>\\d{2}\\.\\d)     # mpg field is of the form dd.d\n",
    "                \\s*                    # skip white spaces\n",
    "                (?P<cyl>\\d)\\.          # cylinders field is of the form d., only want d\n",
    "                .*                     # skip all intervening stuff, greedy match\n",
    "                (?P<yy>\\d{2})\\.        # year is of form dd., only want dd\n",
    "                \\s*                    # skip whitespaces\n",
    "                \\d\\.                   # origin is of the form d.\n",
    "                .*                     # skip intervening stuff\n",
    "                (?P<name>\".*\")         # car name is in double quotes, want double quotes\n",
    "            \"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mpg': '18.0', 'cyl': '8', 'yy': '70', 'name': '\"chevrolet chevelle malibu\"'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = car_reg.match(test_str)\n",
    "res.groupdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"chevrolet chevelle malibu\",1970,8,18.0\n"
     ]
    }
   ],
   "source": [
    "res = car_reg.match(test_str)\n",
    "if res:\n",
    "    car_dict = res.groupdict()\n",
    "    keys = ['name','yy','cyl','mpg']\n",
    "    values = [car_dict[k] for k in keys]\n",
    "    values[1] = '19' + values[1]\n",
    "    print(','.join(values))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice the string join method above<br>\n",
    "Iterable for join must have string values, otherwise won't work**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print a few lines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_filter(in_line):\n",
    "    res = car_reg.match(in_line)\n",
    "    if res:\n",
    "        car_dict = res.groupdict()\n",
    "        keys = ['name','yy','cyl','mpg']\n",
    "        values = [car_dict[k] for k in keys]\n",
    "        values[1] = '19' + values[1]\n",
    "        return ','.join(values) \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"chevrolet chevelle malibu\",1970,8,18.0\n",
      "\"buick skylark 320\",1970,8,15.0\n",
      "\"plymouth satellite\",1970,8,18.0\n",
      "\"amc rebel sst\",1970,8,16.0\n",
      "\"ford torino\",1970,8,17.0\n",
      "\"ford galaxie 500\",1970,8,15.0\n",
      "\"chevrolet impala\",1970,8,14.0\n",
      "\"plymouth fury iii\",1970,8,14.0\n",
      "\"pontiac catalina\",1970,8,14.0\n",
      "\"amc ambassador dpl\",1970,8,15.0\n",
      "\"dodge challenger se\",1970,8,15.0\n"
     ]
    }
   ],
   "source": [
    "for i,line in enumerate(open(\"auto-mpg-original.txt\")):\n",
    "    out_line = my_filter(line)\n",
    "    if out_line:\n",
    "        print(my_filter(line))\n",
    "    if i > 14:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The 5 lines immediately before that for \"dodge challenger se\" in the file are rejected because the first field '(NA)' doesn't meet the regular expression requirement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 2: Using String split\n",
    "**This alternative wasn't covered in class, but it's based on material we have covered before in basic Python, so I am leaving this as an exercise for you to go over.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0,8,1970,\"chevrolet\n",
      "15.0,8,1970,\"buick\n"
     ]
    }
   ],
   "source": [
    "for i,line in enumerate(open(\"auto-mpg-original.txt\")):\n",
    "    flds = line.split()  # on white space\n",
    "    out_flds = []\n",
    "    out_flds.append(flds[0])\n",
    "    out_flds.append(flds[1][:-1])\n",
    "    out_flds.append('19' + flds[6][:-1])\n",
    "    out_flds.append(flds[8])\n",
    "    print(','.join(out_flds))\n",
    "    if i > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hmm, the car name gets truncated because it's got a space in it, and split will break it up into parts. Sow do we address this? We could simply grab all the remainging fields at the end, and concatenate them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 3: expected str instance, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m out_flds\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m19\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m flds[\u001b[38;5;241m6\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      7\u001b[0m out_flds\u001b[38;5;241m.\u001b[39mappend(flds[\u001b[38;5;241m8\u001b[39m:])\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_flds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 3: expected str instance, list found"
     ]
    }
   ],
   "source": [
    "for i,line in enumerate(open(\"auto-mpg-original.txt\")):\n",
    "    flds = line.split()  # on white space\n",
    "    out_flds = []\n",
    "    out_flds.append(flds[0])\n",
    "    out_flds.append(flds[1][:-1])\n",
    "    out_flds.append('19' + flds[6][:-1])\n",
    "    out_flds.append(flds[8:])\n",
    "    print(','.join(out_flds))\n",
    "    if i > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Above, join is expected strings in the iterable, but finds a list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['\"chevrolet', 'chevelle', 'malibu\"']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flds = line.split()  # on white space\n",
    "out_flds = []\n",
    "out_flds.append(flds[8:])\n",
    "out_flds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The car name parts are broken up and gathered into a list. We don't want a list, instead we want a single string out of the parts. We can get this by joining the list items around a space.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"chevrolet chevelle malibu\"']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_flds = []\n",
    "out_flds.append(' '.join(flds[8:]))\n",
    "out_flds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0,8,1970,\"chevrolet chevelle malibu\"\n",
      "15.0,8,1970,\"buick skylark 320\"\n"
     ]
    }
   ],
   "source": [
    "# need to join the flds[8:] list items using a space\n",
    "for i,line in enumerate(open(\"auto-mpg-original.txt\")):\n",
    "    flds = line.split()  # on white space\n",
    "    out_flds = []\n",
    "    out_flds.append(flds[0])\n",
    "    out_flds.append(flds[1][:-1])\n",
    "    out_flds.append('19' + flds[6][:-1])\n",
    "    out_flds.append(' '.join(flds[8:]))\n",
    "    print(','.join(out_flds))\n",
    "    if i > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">So why use regexp instead of string split?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If fields are missing, or incorrectly formatted, much easier with regexp because you specify exact formats for all fields. With split, you will need to read, then check if there are required number of fields, then check each accepted field for correctness of type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: UCI Iris Dataset - CSV File\n",
    "[Iris Dataset](https://archive.ics.uci.edu/dataset/53/iris)\n",
    "\n",
    "This file (*iris-messy.csv*) has 5 columns (fields): sepal_length, sepal_width, petal_length, petal_width, iris_type\n",
    "\n",
    "I have deliberately introduced errors in the dataset so you get a feel for what kinds of errors you might generally expect, and how to take corrective action. \n",
    "\n",
    "These are some of the kinds of errors you might see in datasets in general:\n",
    "- Too many fields\n",
    "- Too few fields\n",
    "- Missing value for field\n",
    "- Unknown value (e.g. ?,NA instead of actual value)\n",
    "- Non-numeric value when numeric is expected\n",
    "\n",
    "Other errors are possible (such as outlier values), and we will tackle some of then when we study the Pandas library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Import the csv module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Make sure there are exactly 5 fields in each row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "009 >>> ['4.4', '2', '9', '1.4', '0.2', 'Iris-setosa']\n",
      "064 >>> ['6.1', '4.7', '1.4', 'Iris-versicolor']\n",
      "078 >>> ['6.7', '3.0', '4.5', '1.7', '6.5', 'Iris-versicolor']\n",
      "103 >>> ['7', '1', '3.0', '5.9', '2.1', 'Iris-virginica']\n",
      "113 >>> ['6.8', '3.0', '5.5', '2.1']\n",
      "152 >>> []\n"
     ]
    }
   ],
   "source": [
    "with open('iris-messy.csv') as irisfile:      # using the with statement\n",
    "    \n",
    "    reader = csv.reader(irisfile)             # set up CSV reader from file\n",
    "    \n",
    "    next(reader)                              # skip first line of column (field) names\n",
    "    \n",
    "    for num,row in enumerate(reader):         # row will be a list of all column (field) values\n",
    "        if len(row) != 5:                     # lines that have too many or too few columns (fields)\n",
    "            print(f'{(num+1):03} >>> {row}')  # pad row number with leading zeros as needed for 3 digits width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'18.0   8.   307.0      130.0      3504.      12.0   70.  1.\\t\"chevrolet chevelle malibu\"': '15.0   8.   350.0      165.0      3693.      11.5   70.  1.\\t\"buick skylark 320\"'}\n",
      "{'18.0   8.   307.0      130.0      3504.      12.0   70.  1.\\t\"chevrolet chevelle malibu\"': '18.0   8.   318.0      150.0      3436.      11.0   70.  1.\\t\"plymouth satellite\"'}\n",
      "{'18.0   8.   307.0      130.0      3504.      12.0   70.  1.\\t\"chevrolet chevelle malibu\"': '16.0   8.   304.0      150.0      3433.      12.0   70.  1.\\t\"amc rebel sst\"'}\n",
      "{'18.0   8.   307.0      130.0      3504.      12.0   70.  1.\\t\"chevrolet chevelle malibu\"': '17.0   8.   302.0      140.0      3449.      10.5   70.  1.\\t\"ford torino\"'}\n",
      "{'18.0   8.   307.0      130.0      3504.      12.0   70.  1.\\t\"chevrolet chevelle malibu\"': '15.0   8.   429.0      198.0      4341.      10.0   70.  1.\\t\"ford galaxie 500\"'}\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "\n",
    "reader = csv.DictReader(open('./data/Auto MPG Original.csv'))\n",
    "for index,row in enumerate(reader):\n",
    "    print(row)\n",
    "    if index > 3:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
